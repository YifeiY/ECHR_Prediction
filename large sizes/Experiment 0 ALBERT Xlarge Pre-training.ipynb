{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bam/Desktop/ECHR Publication Experiments'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = COURPUS_DIR = '/home/bam/Desktop/ECHR Publication Experiments/DS/corpus.txt'\n",
    "BERT_BASE_DIR =\"/home/bam/Desktop/ECHR Publication Experiments/albert-master\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!test -d albert || git clone https://github.com/google-research/albert albert\n",
    "if not 'albert' in sys.path:\n",
    "  sys.path += ['albert']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Reading from input files ***\n",
      "I0618 00:15:26.083496 140702571501376 create_pretraining_data.py:631] *** Reading from input files ***\n",
      "INFO:tensorflow:  /home/bam/Desktop/ECHR Publication Experiments/DS/corpus.txt\n",
      "I0618 00:15:26.083613 140702571501376 create_pretraining_data.py:633]   /home/bam/Desktop/ECHR Publication Experiments/DS/corpus.txt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python -m albert.create_pretraining_data\\\n",
    "  --input_file=\"/home/bam/Desktop/ECHR Publication Experiments/DS/corpus.txt\"\\\n",
    "  --output_file=\"/home/bam/Desktop/ECHR Publication Experiments/albert-master/pre-trained/albert_xlarge/further/tf_examples.tfrecord\"\\\n",
    "  --vocab_file=\"/home/bam/Desktop/ECHR Publication Experiments/albert-master/pre-trained/albert_xlarge/30k-clean.vocab\"\\\n",
    "  --do_lower_case=True\\\n",
    "  --max_seq_length=512\\\n",
    "  --max_predictions_per_seq=77\\\n",
    "  --masked_lm_prob=0.15\\\n",
    "  --random_seed=12345\\\n",
    "  --dupe_factor=10\\\n",
    "  --do_whole_word_mask=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Input Files ***\n",
      "I0618 12:54:30.388302 140412530931520 run_pretraining.py:484] *** Input Files ***\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fb3f6afa9e0>) includes params argument, but params are not passed to Estimator.\n",
      "W0618 12:54:30.388558 140412530931520 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fb3f6afa9e0>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/home/bam/Desktop/ECHR Publication Experiments/albert-master/pre-trained/albert_xlarge/further/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb3f6affad0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "I0618 12:54:30.388930 140412530931520 estimator.py:212] Using config: {'_model_dir': '/home/bam/Desktop/ECHR Publication Experiments/albert-master/pre-trained/albert_xlarge/further/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb3f6affad0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "I0618 12:54:30.389045 140412530931520 tpu_context.py:220] _TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "W0618 12:54:30.389133 140412530931520 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.\n",
      "INFO:tensorflow:***** Running training *****\n",
      "I0618 12:54:30.389181 140412530931520 run_pretraining.py:527] ***** Running training *****\n",
      "INFO:tensorflow:  Batch size = 6\n",
      "I0618 12:54:30.389219 140412530931520 run_pretraining.py:528]   Batch size = 6\n",
      "WARNING:tensorflow:From /home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W0618 12:54:30.392675 140412530931520 deprecation.py:506] From /home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0618 12:54:30.392912 140412530931520 deprecation.py:323] From /home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/bam/Desktop/ECHR Publication Experiments/albert/run_pretraining.py:431: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "W0618 12:54:30.400557 140412530931520 deprecation.py:323] From /home/bam/Desktop/ECHR Publication Experiments/albert/run_pretraining.py:431: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "WARNING:tensorflow:From /home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0618 12:54:30.400657 140412530931520 deprecation.py:323] From /home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "ERROR:tensorflow:Error recorded from training_loop: in converted code:\n",
      "    relative to /home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python:\n",
      "\n",
      "    data/ops/readers.py:336 __init__\n",
      "        filenames, compression_type, buffer_size, num_parallel_reads)\n",
      "    data/ops/readers.py:296 __init__\n",
      "        filenames = _create_or_validate_filenames_dataset(filenames)\n",
      "    data/ops/readers.py:56 _create_or_validate_filenames_dataset\n",
      "        filenames = ops.convert_to_tensor(filenames, dtype=dtypes.string)\n",
      "    framework/ops.py:1184 convert_to_tensor\n",
      "        return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\n",
      "    framework/ops.py:1242 convert_to_tensor_v2\n",
      "        as_ref=False)\n",
      "    framework/ops.py:1273 internal_convert_to_tensor\n",
      "        (dtype.name, value.dtype.name, value))\n",
      "\n",
      "    ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: <tf.Tensor 'args_0:0' shape=() dtype=float32>\n",
      "\n",
      "E0618 12:54:30.403167 140412530931520 error_handling.py:75] Error recorded from training_loop: in converted code:\n",
      "    relative to /home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python:\n",
      "\n",
      "    data/ops/readers.py:336 __init__\n",
      "        filenames, compression_type, buffer_size, num_parallel_reads)\n",
      "    data/ops/readers.py:296 __init__\n",
      "        filenames = _create_or_validate_filenames_dataset(filenames)\n",
      "    data/ops/readers.py:56 _create_or_validate_filenames_dataset\n",
      "        filenames = ops.convert_to_tensor(filenames, dtype=dtypes.string)\n",
      "    framework/ops.py:1184 convert_to_tensor\n",
      "        return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\n",
      "    framework/ops.py:1242 convert_to_tensor_v2\n",
      "        as_ref=False)\n",
      "    framework/ops.py:1273 internal_convert_to_tensor\n",
      "        (dtype.name, value.dtype.name, value))\n",
      "\n",
      "    ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: <tf.Tensor 'args_0:0' shape=() dtype=float32>\n",
      "\n",
      "INFO:tensorflow:training_loop marked as finished\n",
      "I0618 12:54:30.403260 140412530931520 error_handling.py:101] training_loop marked as finished\n",
      "WARNING:tensorflow:Reraising captured error\n",
      "W0618 12:54:30.403308 140412530931520 error_handling.py:135] Reraising captured error\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/bam/Desktop/ECHR Publication Experiments/albert/run_pretraining.py\", line 577, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/absl/app.py\", line 299, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/home/bam/Desktop/ECHR Publication Experiments/albert/run_pretraining.py\", line 534, in main\n",
      "    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.num_train_steps)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3035, in train\n",
      "    rendezvous.raise_errors()\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py\", line 136, in raise_errors\n",
      "    six.reraise(typ, value, traceback)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3030, in train\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1188, in _train_model_default\n",
      "    input_fn, ModeKeys.TRAIN))\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1025, in _get_features_and_labels_from_input_fn\n",
      "    self._call_input_fn(input_fn, mode))\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2987, in _call_input_fn\n",
      "    return input_fn(**kwargs)\n",
      "  File \"/home/bam/Desktop/ECHR Publication Experiments/albert/run_pretraining.py\", line 431, in input_fn\n",
      "    cycle_length=cycle_length))\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 1990, in apply\n",
      "    return DatasetV1Adapter(super(DatasetV1, self).apply(transformation_func))\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 1378, in apply\n",
      "    dataset = transformation_func(self)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/experimental/ops/interleave_ops.py\", line 94, in _apply_fn\n",
      "    buffer_output_elements, prefetch_input_elements)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/readers.py\", line 226, in __init__\n",
      "    map_func, self._transformation_name(), dataset=input_dataset)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 2713, in __init__\n",
      "    self._function = wrapper_fn._get_concrete_function_internal()\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1853, in _get_concrete_function_internal\n",
      "    *args, **kwargs)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1847, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2147, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2038, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 2707, in wrapper_fn\n",
      "    ret = _wrapper_helper(*args)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 2652, in _wrapper_helper\n",
      "    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\n",
      "  File \"/home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 237, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in converted code:\n",
      "    relative to /home/bam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python:\n",
      "\n",
      "    data/ops/readers.py:336 __init__\n",
      "        filenames, compression_type, buffer_size, num_parallel_reads)\n",
      "    data/ops/readers.py:296 __init__\n",
      "        filenames = _create_or_validate_filenames_dataset(filenames)\n",
      "    data/ops/readers.py:56 _create_or_validate_filenames_dataset\n",
      "        filenames = ops.convert_to_tensor(filenames, dtype=dtypes.string)\n",
      "    framework/ops.py:1184 convert_to_tensor\n",
      "        return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\n",
      "    framework/ops.py:1242 convert_to_tensor_v2\n",
      "        as_ref=False)\n",
      "    framework/ops.py:1273 internal_convert_to_tensor\n",
      "        (dtype.name, value.dtype.name, value))\n",
      "\n",
      "    ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: <tf.Tensor 'args_0:0' shape=() dtype=float32>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m albert.run_pretraining \\\n",
    "  --input_file=\"/home/bam/Desktop/ECHR Publication Experiments/albert-master/pre-trained/albert_xlarge/further/tf_examples.tfrecord\" \\\n",
    "  --output_dir=\"/home/bam/Desktop/ECHR Publication Experiments/albert-master/pre-trained/albert_xlarge/further/\" \\\n",
    "  --init_checkpoint= \"/home/bam/Desktop/ECHR Publication Experiments/albert-master/pre-trained/albert_xlarge/model.ckpt-best\"\\\n",
    "  --albert_config_file=\"/home/bam/Desktop/ECHR Publication Experiments/albert-master/pre-trained/albert_xlarge/albert_config.json\"\\\n",
    "  --do_train True \\\n",
    "  --do_eval True \\\n",
    "  --train_batch_size=6 \\\n",
    "  --eval_batch_size=6 \\\n",
    "  --max_seq_length=512 \\\n",
    "  --max_predictions_per_seq=77 \\\n",
    "  --optimizer='lamb' \\\n",
    "  --learning_rate=.00176 \\\n",
    "  --num_train_steps=10000 \\\n",
    "  --num_warmup_steps=1000 \\\n",
    "  --save_checkpoints_steps=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python create_pretraining_data.py --input_file=\"C:/Users/Yifei/Desktop/ECHR Publication Experiments/DS/corpus.txt\" --output_file=\"/home/bam/Desktop/ECHR Publication Experiments/bert_master/pre-trained/uncased_L-12_H-768_A-12/tf_examples.tfrecord\" --vocab_file=\"C:/Users/Yifei/Desktop/ECHR Publication Experiments/bert_master/pre-trained/uncased_L-12_H-768_A-12/vocab.txt\" --do_lower_case=True --max_seq_length=512 --max_predictions_per_seq=77 --masked_lm_prob=0.15 --random_seed=12345 --dupe_factor=5 --do_whole_word_mask=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python run_pretraining.py --input_file=\"C:/Users/Yifei/Desktop/ECHR Publication Experiments/bert_master/pre-trained/uncased_L-12_H-768_A-12/tf_examples.tfrecord\" --output_dir=\"C:/Users/Yifei/Desktop/ECHR Publication Experiments/bert_master/pre-trained/uncased_L-12_H-768_A-12/pretraining_output\" --do_train=True --do_eval=True --bert_config_file=\"C:/Users/Yifei/Desktop/ECHR Publication Experiments/bert_master/pre-trained/uncased_L-12_H-768_A-12/bert_config.json\" --init_checkpoint=\"C:/Users/Yifei/Desktop/ECHR Publication Experiments/bert_master/pre-trained/uncased_L-12_H-768_A-12/bert_model.ckpt\" --train_batch_size=6 --max_seq_length=512 --max_predictions_per_seq=77 --num_train_steps=10000 --num_warmup_steps=1000 --learning_rate=2e-5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
